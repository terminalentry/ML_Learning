{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c471bf2d",
   "metadata": {},
   "source": [
    "### üéØ Learning Objectives\n",
    "- Understand what a distribution represents\n",
    "- Distinguish between descriptive and inferential statistics\n",
    "- Visualize and internalize the Central Limit Theorem\n",
    "- Recognize the impact of variance and shape\n",
    "- Build a reusable thinking framework for statistical reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7ecfc",
   "metadata": {},
   "source": [
    "# Deep Statistics: Foundations for ML & Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0e488",
   "metadata": {},
   "source": [
    "## 1. What is a Distribution, Really?\n",
    "A distribution tells us how likely values are to appear in a population or process. It encodes *assumptions* we make about reality.\n",
    "\n",
    "- Uniform: all outcomes equally likely\n",
    "- Normal: many small influences combine (CLT basis)\n",
    "- Skewed: one-sided influences, like income or wait times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63f104",
   "metadata": {},
   "source": [
    "#### üîç Analogy: Distributions as City Maps\n",
    "Imagine each distribution as a **map of population density**:\n",
    "- **Normal**: Most people live in the city center\n",
    "- **Exponential**: A few live very far out (rich outliers)\n",
    "- **Uniform**: People evenly spread along a beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41619a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different distributions\n",
    "dists = {\n",
    "    'Normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'Exponential (Skewed)': np.random.exponential(scale=2, size=1000),\n",
    "    'Uniform': np.random.uniform(low=-2, high=2, size=1000)\n",
    "}\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=list(dists.keys()))\n",
    "for i, (name, data) in enumerate(dists.items(), 1):\n",
    "    fig.add_trace(go.Histogram(x=data, name=name, nbinsx=40, opacity=0.75), row=1, col=i)\n",
    "fig.update_layout(title_text='Different Distributions', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec6bcc",
   "metadata": {},
   "source": [
    "üëâ Before you run this: Which of these distributions do you think has a mean that best represents the 'typical' value? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d7677",
   "metadata": {},
   "source": [
    "## 2. Descriptive vs Inferential Thinking\n",
    "Descriptive stats **summarize** what you see (mean, median, std).\n",
    "Inferential stats **predict** what you can't see ‚Äî like population properties from samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate skewed data to compare mean vs median\n",
    "data = np.random.exponential(scale=2, size=1000)\n",
    "mean_val = np.mean(data)\n",
    "median_val = np.median(data)\n",
    "fig = px.histogram(data, nbins=40, title='Mean vs Median in Skewed Data')\n",
    "fig.add_vline(x=mean_val, line_dash='dash', line_color='red', annotation_text='Mean')\n",
    "fig.add_vline(x=median_val, line_dash='dot', line_color='blue', annotation_text='Median')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ad93c",
   "metadata": {},
   "source": [
    "## 3. Central Limit Theorem ‚Äî Visualized\n",
    "Even if a population is skewed, the **mean of repeated samples** will approach a normal distribution.\n",
    "This lets us use normal-based tools like confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed5b92",
   "metadata": {},
   "source": [
    "**Let's unpack the CLT step-by-step:**\n",
    "1. You take multiple random samples from a skewed population\n",
    "2. For each sample, you compute its mean\n",
    "3. You collect all these means and plot their distribution\n",
    "4. That distribution will be *approximately normal*, even if the original data wasn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 1000 sample means from exponential (skewed) distribution\n",
    "means = [np.mean(np.random.exponential(scale=2, size=30)) for _ in range(1000)]\n",
    "fig = px.histogram(means, nbins=50, title='Central Limit Theorem in Action')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b49e35",
   "metadata": {},
   "source": [
    "## 4. Why Variance Matters\n",
    "Two datasets can have the same mean but different spreads (variances), leading to very different behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17102cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare same mean, different std\n",
    "x1 = np.random.normal(loc=0, scale=1, size=1000)\n",
    "x2 = np.random.normal(loc=0, scale=3, size=1000)\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['std=1', 'std=3'])\n",
    "fig.add_trace(go.Histogram(x=x1, nbinsx=50, name='std=1'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=x2, nbinsx=50, name='std=3'), row=1, col=2)\n",
    "fig.update_layout(title='Same Mean, Different Variance', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11939114",
   "metadata": {},
   "source": [
    "### ‚úÖ Concept Check\n",
    "1. What would happen to the spread of the sampling distribution if we increased the sample size from 30 to 100?\n",
    "2. Why does the mean of means still reflect the original population mean?\n",
    "3. When does CLT fail to apply?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a466a1d",
   "metadata": {},
   "source": [
    "## üß† In ML Terms:\n",
    "- Distribution shape matters in **assumption-heavy models** (like Naive Bayes, Linear Regression)\n",
    "- Understanding variance helps in **bias-variance tradeoff**\n",
    "- CLT justifies using **confidence intervals** in model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7da7e",
   "metadata": {},
   "source": [
    "## üéì Stretch Challenge\n",
    "- Create your own synthetic population with a weird distribution (e.g., bimodal)\n",
    "- Run the CLT experiment on it and see what happens\n",
    "- Try increasing the sample size ‚Äî what stabilizes first: the mean or the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818ea17",
   "metadata": {},
   "source": [
    "### üßæ Summary Card\n",
    "**Stat Tools You Used:**\n",
    "- Mean, median\n",
    "- Histogram\n",
    "- Sampling\n",
    "- Central Limit Theorem\n",
    "- Variance and standard deviation\n",
    "\n",
    "**Mental Model:** Shape ‚Üí Spread ‚Üí Center ‚Üí Position\n",
    "\n",
    "**Next Step:** Confidence intervals, hypothesis testing, inference"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
