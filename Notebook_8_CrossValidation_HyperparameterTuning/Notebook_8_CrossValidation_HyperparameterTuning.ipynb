{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87510421",
   "metadata": {},
   "source": [
    "# Notebook 8: Cross-Validation & Hyperparameter Tuning\n",
    "\n",
    "Model performance on the training set is often misleading. To generalize well, we use **cross-validation** to select model complexity and prevent overfitting.\n",
    "\n",
    "Goals:\n",
    "- Understand train/test splits and cross-validation\n",
    "- Use `GridSearchCV` to tune regularization strength\n",
    "- Compare Ridge and Lasso performance\n",
    "- Visualize error vs alpha curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d228ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8a875",
   "metadata": {},
   "source": [
    "## Step 1: Generate Noisy Polynomial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = 0.5 * X[:, 0]**3 - X[:, 0]**2 + 2 * X[:, 0] + 3 + np.random.normal(0, 20, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82385d54",
   "metadata": {},
   "source": [
    "## Step 2: Ridge Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-4, 4, 20)\n",
    "ridge_pipeline = make_pipeline(PolynomialFeatures(degree=10), StandardScaler(), Ridge())\n",
    "\n",
    "param_grid = {'ridge__alpha': alphas}\n",
    "grid_ridge = GridSearchCV(ridge_pipeline, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "print(f\"Best alpha for Ridge: {grid_ridge.best_params_['ridge__alpha']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5971b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_ridge.cv_results_)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(alphas, -results['mean_test_score'], marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Cross-validated MSE')\n",
    "plt.title('Ridge: Alpha vs CV Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a34c57",
   "metadata": {},
   "source": [
    "## Step 3: Lasso Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pipeline = make_pipeline(PolynomialFeatures(degree=10), StandardScaler(), Lasso(max_iter=10000))\n",
    "param_grid = {'lasso__alpha': alphas}\n",
    "grid_lasso = GridSearchCV(lasso_pipeline, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "print(f\"Best alpha for Lasso: {grid_lasso.best_params_['lasso__alpha']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105517f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_lasso.cv_results_)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(alphas, -results['mean_test_score'], marker='o', color='darkred')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Cross-validated MSE')\n",
    "plt.title('Lasso: Alpha vs CV Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4052dba",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_best = grid_ridge.best_estimator_\n",
    "lasso_best = grid_lasso.best_estimator_\n",
    "\n",
    "mse_ridge_test = mean_squared_error(y_test, ridge_best.predict(X_test))\n",
    "mse_lasso_test = mean_squared_error(y_test, lasso_best.predict(X_test))\n",
    "\n",
    "print(f\"Ridge Test MSE: {mse_ridge_test:.2f}\")\n",
    "print(f\"Lasso Test MSE: {mse_lasso_test:.2f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
