{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8c2a91",
   "metadata": {},
   "source": [
    "# Notebook 6: Feature Transformation and Polynomial Regression\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "- Why and how we transform features\n",
    "- When and how to use polynomial regression\n",
    "- The underlying math and visual intuition\n",
    "\n",
    "**Goal**: Understand the limitations of linearity and how transformations help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ab8ec",
   "metadata": {},
   "source": [
    "## Generate Nonlinear Data\n",
    "\n",
    "We'll simulate data where the relationship is quadratic (not linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2aa664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a non-linear dataset\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = 3 * (X**2) + 2 + np.random.normal(0, 10, size=X.shape)\n",
    "y = y.ravel()  # make y 1D for regression\n",
    "\n",
    "# Visualize\n",
    "px.scatter(x=X.ravel(), y=y, labels={'x': 'X', 'y': 'y'}, title='Generated Quadratic Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7aaa0",
   "metadata": {},
   "source": [
    "## Step 1: Try Linear Regression\n",
    "\n",
    "We'll first fit a simple linear model to the data and observe poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X, y)\n",
    "y_pred_linear = model_linear.predict(X)\n",
    "\n",
    "# Plot\n",
    "fig = px.scatter(x=X.ravel(), y=y, opacity=0.6, labels={'x': 'X', 'y': 'y'}, title='Linear Regression on Quadratic Data')\n",
    "fig.add_scatter(x=X.ravel(), y=y_pred_linear, mode='lines', name='Linear Fit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54acf8",
   "metadata": {},
   "source": [
    "## Step 2: Fit Polynomial Regression\n",
    "\n",
    "We'll now fit a polynomial model of degree 2.\n",
    "\n",
    "**Math background**:\n",
    "Polynomial regression fits:  \n",
    "\\[ y = \\beta_0 + \\beta_1x + \\beta_2x^2 + \\dots + \\beta_kx^k \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_model.fit(X, y)\n",
    "y_pred_poly = poly_model.predict(X)\n",
    "\n",
    "# Plot\n",
    "fig = px.scatter(x=X.ravel(), y=y, opacity=0.6, labels={'x': 'X', 'y': 'y'}, title='Polynomial Regression (Degree 2)')\n",
    "fig.add_scatter(x=X.ravel(), y=y_pred_poly, mode='lines', name='Polynomial Fit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2c438",
   "metadata": {},
   "source": [
    "## Step 3: Compare Performance\n",
    "\n",
    "Weâ€™ll use **Mean Squared Error (MSE)** to evaluate both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_linear = mean_squared_error(y, y_pred_linear)\n",
    "mse_poly = mean_squared_error(y, y_pred_poly)\n",
    "print(f'MSE Linear: {mse_linear:.2f}')\n",
    "print(f'MSE Polynomial (deg 2): {mse_poly:.2f}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
